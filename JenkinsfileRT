// Obtain files from source control system.
if (utils.scm_checkout()) return

// Select a tree on Artifactory to provide input and truth data
artifactory_env = "dev"
if (env.ARTIFACTORY_ENV) {
    artifactory_env = env.ARTIFACTORY_ENV
}

codecov_install = "curl -Os https://uploader.codecov.io/latest/linux/codecov && chmod +x codecov"

// Allow modification of the job configuration, affects all relevant
// build configs.
// Pass this object in the argument list to the`run()` function below
// to apply these settings to the job's execution.
jobconfig = new JobConfig()
jobconfig.credentials = [
        ['drizzlepac_codecov', 'CODECOV_TOKEN']
    ]
jobconfig.post_test_summary = true

// Configure artifactory ingest
data_config = new DataConfig()
data_config.server_id = 'bytesalad'
data_config.root = 'clone/tests_output'
data_config.match_prefix = '(.*)_result' // .json is appended automatically

// Unit testing config
bc_unit = new BuildConfig()
bc_unit.runtime.add('CFLAGS=-std=gnu99')
bc_unit.env_vars = ['TEST_BIGDATA=https://bytesalad.stsci.edu/artifactory']
bc_unit.build_cmds = ["pip install numpy astropy codecov pytest-cov ci-watson",
		 "pip install --upgrade -e '.[test]'",
                 "pip freeze"]
bc_unit.test_cmds = ["pytest --env=${artifactory_env} --cov=./ --basetemp=tests_output --junitxml=results.xml",
                 "codecov"]
bc_unit.test_configs = [data_config]
bc_unit.failedFailureThresh = 0

// Unit testing (dev) config
bc_unit_dev = utils.copy(bc_unit)
bc_unit_dev.build_cmds = ["pip install numpy astropy codecov pytest-cov ci-watson || true",
                 "pip install -r requirements-dev.txt --upgrade -e '.[test]' || true",
                 "pip freeze || true"]
bc_unit_dev.test_cmds = ["pytest --env=${artifactory_env} --cov=./ --basetemp=tests_output --junitxml=results.xml",
                "codecov"]
bc_unit_dev.failedFailureThresh = 1000

// Regression testing config
bc_rt = utils.copy(bc_unit)
bc_rt.test_cmds = ["pytest --env=${artifactory_env} --cov=./ --basetemp=tests_output --junitxml=results.xml --slow --bigdata",
                 "codecov"]


// Linux
bc1 = utils.copy(bc_unit)
bc1.nodetype = 'linux'
bc1.name = '3.11-unit'
bc1.conda_packages = ['python=3.11']

bc2 = utils.copy(bc_unit_dev)
bc2.name = '3.11-dev'
bc2.nodetype = 'linux'
bc2.conda_packages = ['python=3.11']

bc3 = utils.copy(bc_unit)
bc3.nodetype = 'linux'
bc3.name = '3.12-unit'
bc3.conda_packages = ['python=3.12']

bc4 = utils.copy(bc_unit_dev)
bc4.nodetype = 'linux'
bc4.name = '3.12-dev'
bc4.conda_packages = ['python=3.12']

// Mac OS
bc5 = utils.copy(bc_unit)
bc5.nodetype = 'macos_x86_64'
bc5.name = '3.11-unit'
bc5.conda_packages = ['python=3.11']

bc6 = utils.copy(bc_unit_dev)
bc6.nodetype = 'macos_x86_64'
bc6.name = '3.11-unit-dev'
bc6.conda_packages = ['python=3.11']

bc7 = utils.copy(bc_unit)
bc7.nodetype = 'macos_x86_64'
bc7.name = '3.12-unit'
bc7.conda_packages = ['python=3.12']

bc8 = utils.copy(bc_unit_dev)
bc8.nodetype = 'macos_x86_64'
bc8.name = '3.12-unit-dev'
bc8.conda_packages = ['python=3.12']

bc9 = utils.copy(bc_rt)
bc9.nodetype = 'macos_x86_64'
bc9.name = '3.12-rt'
bc9.conda_packages = ['python=3.12']

// Iterate over configurations that define the (distributed) build matrix.
// Spawn a host (or workdir) for each combination and run in parallel.
// Also apply the job configuration defined in `jobconfig` above.
utils.run([bc1, bc2, bc3, bc4, bc5, bc6, bc7, bc8, bc9, jobconfig])
